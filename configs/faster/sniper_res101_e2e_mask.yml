# --------------------------------------------------------------
# SNIPER: Efficient Multi-Scale Training
# Licensed under The Apache-2.0 License [see LICENSE for details]
# by Mahyar Najibi, Bharat Singh
# --------------------------------------------------------------
---
MXNET_VERSION: "mxnet"
output_path: "./output/sniper_res_101_bn_mask"
symbol: resnet_mx_101_e2e_mask
gpus: '0,1,2,3,4,5,6,7'
CLASS_AGNOSTIC: true

default:
  kvstore: device
network:
  pretrained: "./data/pretrained_model/resnet_mx_101_open"
  pretrained_epoch: 0
  PIXEL_MEANS:
  - 103.939
  - 116.779
  - 123.68
  RPN_FEAT_STRIDE: 16
  FIXED_PARAMS:
  - conv0
  - bn0
  - stage1
  ANCHOR_RATIOS:
  - 0.5
  - 1
  - 2
  ANCHOR_SCALES:
  - 2
  - 4
  - 7
  - 10
  - 13
  - 16
  - 24
  NUM_ANCHORS: 21

dataset:
  NUM_CLASSES: 81
  dataset: coco
  dataset_path: "./data/coco"
  image_set: train2014+val2014
  root_path: "./data"
  test_image_set: test-dev2015
  proposal: rpn

TRAIN:
  # Whether to use C++ or python code for chip generation
  CPP_CHIPS: true
  # How many parts the dataset should be divided to for parallel chip generation
  # This is used to keep the memory limited
  CHIPS_DB_PARTS: 20

  # Multi-processing params
  # These parameters are used for parallel chip generation, NMS, etc.
  # Please consider adjusting them for your system
  NUM_PROCESS: 64
  NUM_THREAD: 8

  # Whether to train with segmentation mask
  WITH_MASK: true

 # Training scales
  # The scales should be sorted in descending order based on size 
  # (the first scale is the highest resolution and the last scale is the lowest one)
  # Two types of scale definition are supported
  SCALES:
  # 1) You can define scale based on resolutions in pixels
  # [min_resolution, max_resolution]
  # The shortest side of the image is resized to min_resolution while the 
  # longest side is kept less than max_resolution
  # -1 indicates no constraint on min/max resolution
  - !!python/tuple [1400, 2000]
  - !!python/tuple [800, 1280]
  - !!python/tuple [-1, 512]
  
  # 2) Alternatively you can define the scaling factor as below:
  # In this case, the lowest resolution should be the maximum side of image
  # in pixels and all other scales should be defined as a float scaling factor
  # The following are the scales we used in the paper for COCO dataset
  # - 3.0
  # - 1.667
  # - 512.0

  # Valid ranges in each scale
  VALID_RANGES:
  - !!python/tuple [-1,80]
  - !!python/tuple [32,150]
  - !!python/tuple [120,-1]

  lr: 0.015 
  lr_step: '5.33'
  warmup: true
  fp16: true
  warmup_lr: 0.0005 
  wd: 0.0001
  scale: 100.0
  warmup_step: 1000
  begin_epoch: 0
  end_epoch: 7
  # whether resume training
  # whether flip image
  FLIP: true
  # whether shuffle image
  SHUFFLE: true
  # Number of images per GPU
  BATCH_IMAGES: 10
  # e2e changes behavior of anchor loader and metric
  END2END: true

  # R-CNN
  # rcnn rois batch size
  BATCH_ROIS: -1
  BATCH_ROIS_OHEM: 256
  # rcnn rois sampling params
  FG_FRACTION: 0.25
  FG_THRESH: 0.5
  BG_THRESH_HI: 0.5
  BG_THRESH_LO: 0.0
  # rcnn bounding box regression params
  BBOX_REGRESSION_THRESH: 0.5
  BBOX_WEIGHTS:
  - 1.0
  - 1.0
  - 1.0
  - 1.0

  # RPN anchor loader
  # rpn anchors batch size
  RPN_BATCH_SIZE: 256
  # rpn anchors sampling params
  RPN_FG_FRACTION: 0.5
  RPN_POSITIVE_OVERLAP: 0.5
  RPN_NEGATIVE_OVERLAP: 0.4
  RPN_CLOBBER_POSITIVES: false
  # rpn bounding box regression params
  RPN_BBOX_WEIGHTS:
  - 1.0
  - 1.0
  - 1.0
  - 1.0
  RPN_POSITIVE_WEIGHT: -1.0
  # used for end2end training
  # RPN proposal
  CXX_PROPOSAL: false
  RPN_NMS_THRESH: 0.7
  RPN_PRE_NMS_TOP_N: 6000
  RPN_POST_NMS_TOP_N: 300
  RPN_MIN_SIZE: 0
  # approximate bounding box regression
  BBOX_NORMALIZATION_PRECOMPUTED: true
  BBOX_MEANS:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  BBOX_STDS:
  - 0.1
  - 0.1
  - 0.2
  - 0.2
TEST:
  # Maximum number of detections per image
  # Set to -1 to disable
  MAX_PER_IMAGE: 200

  # Whether to do multi-scale inference
  SCALES:
  - !!python/tuple [1400, 2000]
  - !!python/tuple [800, 1280]
  - !!python/tuple [480, 512]

  # Number of images per gpu for each scale
  BATCH_IMAGES:
  - 2
  - 2
  - 4

  # Number of concurrent jobs used for inference
  # if greater than 1, the roidb is distributed over
  # concurrent jobs to increase throughput
  CONCURRENT_JOBS: 2

  # Ranges to specify valid proposal length
  # in each of the test scale, square area
  # would be computed based on the lengths
  # to invalidate, -1 means unbounded, use
  # -1 everywhere if you want to have all proposals
  VALID_RANGES:
  - !!python/tuple [-1,90]
  - !!python/tuple [32,180]
  - !!python/tuple [75,-1]

  # Use rpn to generate proposal
  HAS_RPN: true

  # RPN Parameters
  RPN_NMS_THRESH: 0.7
  RPN_PRE_NMS_TOP_N: 6000
  RPN_POST_NMS_TOP_N: 300
  RPN_MIN_SIZE: 0
  PROPOSAL_NMS_THRESH: 0.7
  PROPOSAL_PRE_NMS_TOP_N: 20000
  PROPOSAL_POST_NMS_TOP_N: 2000
  PROPOSAL_MIN_SIZE: 0

  # NMS Parameters
  # Whether to apply NMS based on threshold or sigma
  NMS: -1 #0.45
  NMS_SIGMA: 0.55

  # Which epoch of the training be used for testing
  TEST_EPOCH: 7

  # VISUALIZATION CONFIG
  VISUALIZATION_PATH: './debug/visualization'
  # Whether to visualize all intermediate scales
  # before aggregation (when doing multi-scale inference)
  # If False, only final detections are saved to 
  # VISUALIZATION_PATH
  VISUALIZE_INTERMEDIATE_SCALES: false

  # PROPOSAL EXTRACTION FLAGS
  # If true only would extract proposals
  EXTRACT_PROPOSALS: false

  # The folder path to be used for saving proposals
  PROPOSAL_SAVE_PATH: 'output/proposals'

  # Number of proposals extracted per scale
  # SCALES and BATCH_IMAGES above would be used to
  # Specify scales and number of images per batch for
  # each scale, no valid ranges would be applied for
  # aggregating proposals
  N_PROPOSAL_PER_SCALE: 300

